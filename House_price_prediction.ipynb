{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/exceededdose/house-price-pred?scriptVersionId=190782813\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n\nfrom scipy.stats import norm\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:17:04.757599Z","iopub.execute_input":"2024-08-01T17:17:04.758047Z","iopub.status.idle":"2024-08-01T17:17:07.879238Z","shell.execute_reply.started":"2024-08-01T17:17:04.758008Z","shell.execute_reply":"2024-08-01T17:17:07.877976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_columns = 999\npd.options.display.max_rows = 20","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:17:32.078639Z","iopub.execute_input":"2024-08-01T17:17:32.07921Z","iopub.status.idle":"2024-08-01T17:17:32.08465Z","shell.execute_reply.started":"2024-08-01T17:17:32.07917Z","shell.execute_reply":"2024-08-01T17:17:32.083392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Visualisation","metadata":{}},{"cell_type":"markdown","source":"##### Let's now spend some time doing what is arguably the most important step - understanding the data.\n\nUnderstanding the distribution of various numeric variables\nIf there is some obvious multicollinearity going on, this is the first place to catch it\nHere's where you'll also identify if some predictors directly have a strong association with the outcome variable","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:18:43.233727Z","iopub.execute_input":"2024-08-01T17:18:43.234229Z","iopub.status.idle":"2024-08-01T17:18:43.247357Z","shell.execute_reply.started":"2024-08-01T17:18:43.234196Z","shell.execute_reply":"2024-08-01T17:18:43.245166Z"}}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:20:21.013948Z","iopub.execute_input":"2024-08-01T17:20:21.015465Z","iopub.status.idle":"2024-08-01T17:20:21.133776Z","shell.execute_reply.started":"2024-08-01T17:20:21.015409Z","shell.execute_reply":"2024-08-01T17:20:21.132422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:20:52.870457Z","iopub.execute_input":"2024-08-01T17:20:52.870863Z","iopub.status.idle":"2024-08-01T17:20:52.91696Z","shell.execute_reply.started":"2024-08-01T17:20:52.870828Z","shell.execute_reply":"2024-08-01T17:20:52.915474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in df:\n    if df[column].dtype ==\"float\":\n        df[column]=pd.to_numeric(df[column],downcast=\"float\")\n    if df[column].dtype==\"int64\":\n        df[column] = pd.to_numeric(df[column],downcast = \"integer\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:21:37.239038Z","iopub.execute_input":"2024-08-01T17:21:37.239521Z","iopub.status.idle":"2024-08-01T17:21:37.279993Z","shell.execute_reply.started":"2024-08-01T17:21:37.239474Z","shell.execute_reply":"2024-08-01T17:21:37.278403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:21:52.718798Z","iopub.execute_input":"2024-08-01T17:21:52.720238Z","iopub.status.idle":"2024-08-01T17:21:52.750647Z","shell.execute_reply.started":"2024-08-01T17:21:52.720192Z","shell.execute_reply":"2024-08-01T17:21:52.749282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Benefit, increase the processing speed, decreasing file size\n\nwe can able to achive the reduce from 924.0+ KB to 596.1+ KB","metadata":{}},{"cell_type":"markdown","source":"### Basic Checks","metadata":{}},{"cell_type":"markdown","source":"#### Checking for missing values in the dataframe","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10,5))\nsns.heatmap(df.head().isna().T)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:24:01.05348Z","iopub.execute_input":"2024-08-01T17:24:01.053931Z","iopub.status.idle":"2024-08-01T17:24:01.873479Z","shell.execute_reply.started":"2024-08-01T17:24:01.053897Z","shell.execute_reply":"2024-08-01T17:24:01.872272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_df = pd.DataFrame(df.isna().sum())\nnull_df.reset_index(drop = False, inplace = True)\nnull_df[null_df[0] != 0].rename(columns = {'index':'Feature', 0:'Count of missing values'})","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:24:22.849234Z","iopub.execute_input":"2024-08-01T17:24:22.849629Z","iopub.status.idle":"2024-08-01T17:24:22.879286Z","shell.execute_reply.started":"2024-08-01T17:24:22.849598Z","shell.execute_reply":"2024-08-01T17:24:22.877922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### - There is no values for Misc Feature\n    - Drop columns since it does not have any values","metadata":{}},{"cell_type":"code","source":"df.drop(columns = ['MiscFeature'], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:25:41.899722Z","iopub.execute_input":"2024-08-01T17:25:41.900324Z","iopub.status.idle":"2024-08-01T17:25:41.91542Z","shell.execute_reply.started":"2024-08-01T17:25:41.900281Z","shell.execute_reply":"2024-08-01T17:25:41.914087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_dict = {'Feature':[], 'Len':[], 'Values':[]}\nfor x in df:\n    temp_dict['Feature'].append(x)\n    temp_dict['Len'].append(len(df[x].unique()))\n    temp_dict['Values'].append(df[x].unique())","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:25:56.009078Z","iopub.execute_input":"2024-08-01T17:25:56.009592Z","iopub.status.idle":"2024-08-01T17:25:56.044421Z","shell.execute_reply.started":"2024-08-01T17:25:56.009557Z","shell.execute_reply":"2024-08-01T17:25:56.043288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_field = pd.DataFrame(temp_dict)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:26:08.303606Z","iopub.execute_input":"2024-08-01T17:26:08.304057Z","iopub.status.idle":"2024-08-01T17:26:08.311581Z","shell.execute_reply.started":"2024-08-01T17:26:08.304023Z","shell.execute_reply":"2024-08-01T17:26:08.309879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Checking the length, unique values, missing values, data types, and percentage of missing values","metadata":{}},{"cell_type":"code","source":"data_field = data_field.sort_values(by = ['Len'], ascending = False).reset_index(drop = True)\ndata_field = data_field.merge(null_df, left_on = 'Feature', right_on = 'index').drop(columns = 'index').rename(columns = {0:'Missing Values'})","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:26:45.453962Z","iopub.execute_input":"2024-08-01T17:26:45.45436Z","iopub.status.idle":"2024-08-01T17:26:45.474092Z","shell.execute_reply.started":"2024-08-01T17:26:45.454333Z","shell.execute_reply":"2024-08-01T17:26:45.47261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_field['Data Types'] = data_field.progress_apply(lambda x: df[x['Feature']].dtype, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:26:59.149476Z","iopub.execute_input":"2024-08-01T17:26:59.150006Z","iopub.status.idle":"2024-08-01T17:26:59.19152Z","shell.execute_reply.started":"2024-08-01T17:26:59.149969Z","shell.execute_reply":"2024-08-01T17:26:59.189953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_field['Percentage of missing values'] = data_field.progress_apply(lambda x: x['Missing Values'] / len(df) * 100,axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:27:17.589479Z","iopub.execute_input":"2024-08-01T17:27:17.590002Z","iopub.status.idle":"2024-08-01T17:27:17.620617Z","shell.execute_reply.started":"2024-08-01T17:27:17.589955Z","shell.execute_reply":"2024-08-01T17:27:17.618998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_field.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:27:30.993604Z","iopub.execute_input":"2024-08-01T17:27:30.994062Z","iopub.status.idle":"2024-08-01T17:27:31.01936Z","shell.execute_reply.started":"2024-08-01T17:27:30.994028Z","shell.execute_reply":"2024-08-01T17:27:31.017972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Missing Data","metadata":{}},{"cell_type":"code","source":"missing_col_num_df = data_field[(data_field['Data Types'] != 'object') & (data_field['Missing Values'] != 0)]\nmissing_col_num = data_field[(data_field['Data Types'] != 'object') & (data_field['Missing Values'] != 0)]['Feature'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:28:53.159534Z","iopub.execute_input":"2024-08-01T17:28:53.160046Z","iopub.status.idle":"2024-08-01T17:28:53.170674Z","shell.execute_reply.started":"2024-08-01T17:28:53.160011Z","shell.execute_reply":"2024-08-01T17:28:53.168818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# numerical column missing values\nmissing_col_num_df","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:29:57.894656Z","iopub.execute_input":"2024-08-01T17:29:57.895176Z","iopub.status.idle":"2024-08-01T17:29:57.914907Z","shell.execute_reply.started":"2024-08-01T17:29:57.89514Z","shell.execute_reply":"2024-08-01T17:29:57.913535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replacing missing values in numeric columns with average value since the missing percentage is not too high\nfor x in missing_col_num:\n    df[x].fillna(df[x].mean(), inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:30:11.824332Z","iopub.execute_input":"2024-08-01T17:30:11.824866Z","iopub.status.idle":"2024-08-01T17:30:11.835161Z","shell.execute_reply.started":"2024-08-01T17:30:11.824827Z","shell.execute_reply":"2024-08-01T17:30:11.833665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# categorical column missing values\nmissing_col_cat = data_field[(data_field['Data Types'] == 'object') & (data_field['Missing Values'] != 0)].sort_values(by = 'Percentage of missing values')\nmissing_col_cat","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:30:21.245598Z","iopub.execute_input":"2024-08-01T17:30:21.246021Z","iopub.status.idle":"2024-08-01T17:30:21.274305Z","shell.execute_reply.started":"2024-08-01T17:30:21.245989Z","shell.execute_reply":"2024-08-01T17:30:21.27307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# segmenting the categorical columns with less than 10 % missing values\nmissing_col_cat_less10_df = missing_col_cat[missing_col_cat['Percentage of missing values'] < 10]\nmissing_col_cat_less10 = missing_col_cat_less10_df['Feature'].tolist()\n\n# segmenting the categorical columns with more than 10 % missing values\nmissing_col_cat_great10_df = missing_col_cat[missing_col_cat['Percentage of missing values'] > 10]\nmissing_col_cat_great10 = missing_col_cat_great10_df['Feature'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:30:53.57949Z","iopub.execute_input":"2024-08-01T17:30:53.579931Z","iopub.status.idle":"2024-08-01T17:30:53.589994Z","shell.execute_reply.started":"2024-08-01T17:30:53.579875Z","shell.execute_reply":"2024-08-01T17:30:53.588591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Less than 10% missing values\nmissing_col_cat_less10_df","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:31:07.374193Z","iopub.execute_input":"2024-08-01T17:31:07.374631Z","iopub.status.idle":"2024-08-01T17:31:07.398822Z","shell.execute_reply.started":"2024-08-01T17:31:07.3746Z","shell.execute_reply":"2024-08-01T17:31:07.397583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for feature with less than 10% missing values, impute the mode directly since the missing percentage is not too high\nfor x in missing_col_cat_less10:\n    df[x] = df[x].fillna(df[x].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:31:37.143662Z","iopub.execute_input":"2024-08-01T17:31:37.144198Z","iopub.status.idle":"2024-08-01T17:31:37.168122Z","shell.execute_reply.started":"2024-08-01T17:31:37.144162Z","shell.execute_reply":"2024-08-01T17:31:37.166251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Greater than 10% missing values\nmissing_col_cat_great10_df","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:31:48.518813Z","iopub.execute_input":"2024-08-01T17:31:48.519765Z","iopub.status.idle":"2024-08-01T17:31:48.543316Z","shell.execute_reply.started":"2024-08-01T17:31:48.519719Z","shell.execute_reply":"2024-08-01T17:31:48.542172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the releationship of high missing values column with the target\npal = sns.color_palette(\"mako\", len(df[x].unique()))\nplot_count = 1\nplt.figure(figsize=(20, 15))\nfor x in missing_col_cat_great10:\n    plt.subplot(3, 2, plot_count) \n    plt.title(\"Average SalePrice per \" + x)\n    sns.barplot(data=df[[x, 'SalePrice']].fillna('No value'), x=x, y='SalePrice', estimator=np.mean, palette=pal)\n    plot_count += 1\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:36:33.365092Z","iopub.execute_input":"2024-08-01T17:36:33.365522Z","iopub.status.idle":"2024-08-01T17:36:36.006453Z","shell.execute_reply.started":"2024-08-01T17:36:33.365493Z","shell.execute_reply":"2024-08-01T17:36:36.005163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### Based on the chart above, the columns with missing value has a significant effect to SalePrice value. The null values will be imputed as \"No value\"","metadata":{}},{"cell_type":"code","source":"# for feature with greater than 10% missing values, \n# it is confirmed that even the columns has high missing percentage, it is still significant. Impute the mode to missing values\nfor x in missing_col_cat_great10:\n    df[x] = df[x].fillna(df[x].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:38:12.855147Z","iopub.execute_input":"2024-08-01T17:38:12.855608Z","iopub.status.idle":"2024-08-01T17:38:12.873942Z","shell.execute_reply.started":"2024-08-01T17:38:12.855572Z","shell.execute_reply":"2024-08-01T17:38:12.872206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is the new dataset with no missing values\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:38:27.969868Z","iopub.execute_input":"2024-08-01T17:38:27.970319Z","iopub.status.idle":"2024-08-01T17:38:28.006251Z","shell.execute_reply.started":"2024-08-01T17:38:27.970286Z","shell.execute_reply":"2024-08-01T17:38:28.004687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"markdown","source":"#### Correlation Plotting","metadata":{}},{"cell_type":"code","source":"cols = \"\"\"SalePrice\nOverallQual\nGrLivArea\nGarageCars\nTotalBsmtSF\nFullBath\nYearBuilt\nYearRemodAdd\"\"\"\ncols = cols.split('\\n')\nprint(cols)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:43:37.46426Z","iopub.execute_input":"2024-08-01T17:43:37.464716Z","iopub.status.idle":"2024-08-01T17:43:37.47246Z","shell.execute_reply.started":"2024-08-01T17:43:37.464684Z","shell.execute_reply":"2024-08-01T17:43:37.470985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df[cols], height = 1.5)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:43:52.379811Z","iopub.execute_input":"2024-08-01T17:43:52.38037Z","iopub.status.idle":"2024-08-01T17:44:15.757998Z","shell.execute_reply.started":"2024-08-01T17:43:52.38033Z","shell.execute_reply":"2024-08-01T17:44:15.756223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dist_df = pd.DataFrame(index = ['Skewness', 'Kurtosis'], data = {'Normal':[df['SalePrice'].skew(), df['SalePrice'].kurt()],\n                                                       'log':[np.log1p(df['SalePrice']).skew(), np.log1p(df['SalePrice']).kurt()]})\ndist_df['% change'] = dist_df.apply(lambda x: (x['log'] / x['Normal'] - 1) * 100, axis = 1)\ndist_df","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:44:43.174827Z","iopub.execute_input":"2024-08-01T17:44:43.175349Z","iopub.status.idle":"2024-08-01T17:44:43.198357Z","shell.execute_reply.started":"2024-08-01T17:44:43.175314Z","shell.execute_reply":"2024-08-01T17:44:43.196401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### Implementing log-transformation in the dataset lowers the skewness and kurtosis.","metadata":{}},{"cell_type":"markdown","source":"#### Distribution of saleprice before and after log-transformation","metadata":{}},{"cell_type":"markdown","source":"#### Before","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:45:47.889915Z","iopub.execute_input":"2024-08-01T17:45:47.890394Z","iopub.status.idle":"2024-08-01T17:45:47.896865Z","shell.execute_reply.started":"2024-08-01T17:45:47.89036Z","shell.execute_reply":"2024-08-01T17:45:47.895295Z"}}},{"cell_type":"code","source":"sns.distplot(df['SalePrice'], fit = norm)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:46:13.150202Z","iopub.execute_input":"2024-08-01T17:46:13.150663Z","iopub.status.idle":"2024-08-01T17:46:14.158823Z","shell.execute_reply.started":"2024-08-01T17:46:13.150626Z","shell.execute_reply":"2024-08-01T17:46:14.157333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stats.probplot(df['SalePrice'], plot=plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:46:33.400124Z","iopub.execute_input":"2024-08-01T17:46:33.400573Z","iopub.status.idle":"2024-08-01T17:46:33.701227Z","shell.execute_reply.started":"2024-08-01T17:46:33.400542Z","shell.execute_reply":"2024-08-01T17:46:33.699472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### After","metadata":{}},{"cell_type":"code","source":"sns.distplot(np.log1p(df['SalePrice']), fit = norm)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:46:59.983443Z","iopub.execute_input":"2024-08-01T17:46:59.983935Z","iopub.status.idle":"2024-08-01T17:47:00.433246Z","shell.execute_reply.started":"2024-08-01T17:46:59.983869Z","shell.execute_reply":"2024-08-01T17:47:00.431919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stats.probplot(np.log1p(df['SalePrice']), plot=plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:47:14.485193Z","iopub.execute_input":"2024-08-01T17:47:14.485712Z","iopub.status.idle":"2024-08-01T17:47:14.832739Z","shell.execute_reply.started":"2024-08-01T17:47:14.485672Z","shell.execute_reply":"2024-08-01T17:47:14.831294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### Based on the probability plot, it is more fit when log-transformed","metadata":{}},{"cell_type":"markdown","source":"##### Focusing on the before distribution, we could notice that it is right skewed. Therefore there maybe outliers in the dataset","metadata":{}},{"cell_type":"markdown","source":"#### Checking for outliers","metadata":{}},{"cell_type":"code","source":"sns.set()\nplot_count = 1\nplt.figure(figsize = (20,25))\nfor x in cols:\n    plt.subplot(4,2,plot_count)\n    plt.title(x)\n    sns.boxplot(df[x])\n    plot_count += 1","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:48:23.438972Z","iopub.execute_input":"2024-08-01T17:48:23.43948Z","iopub.status.idle":"2024-08-01T17:48:25.569741Z","shell.execute_reply.started":"2024-08-01T17:48:23.439442Z","shell.execute_reply":"2024-08-01T17:48:25.568539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dist_df = pd.DataFrame(index = ['Skewness', 'Kurtosis'], data = {'Normal':[df['SalePrice'].skew(), df['SalePrice'].kurt()],\n                                                       'log':[np.log1p(df['SalePrice']).skew(), np.log1p(df['SalePrice']).kurt()]})\ndist_df['% change'] = dist_df.apply(lambda x: (x['log'] / x['Normal'] - 1) * 100, axis = 1)\ndist_df","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:49:04.433396Z","iopub.execute_input":"2024-08-01T17:49:04.43384Z","iopub.status.idle":"2024-08-01T17:49:04.455531Z","shell.execute_reply.started":"2024-08-01T17:49:04.433807Z","shell.execute_reply":"2024-08-01T17:49:04.454126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Based on the chart above, saleprice above 500k can be considered as an outlier","metadata":{}},{"cell_type":"markdown","source":"### Implementing log-transformation in the dataset lowers the skewness and kurtosis.\n\n###### Skewness, Kurtosis and Outliers \n\n###### Skewness: \nSkewness is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean.\n\nIf skewness is less than -1 or greater than 1, the distribution is highly skewed. \nIf skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed. \nIf skewness is between -0.5 and 0.5, the distribution is approximately symmetric.\n\n##### Kurtosis: \nKurtosis is a statistical measure that defines how heavily the tails of a distribution differ from the tails of a normal distribution. In other words, kurtosis identifies whether the tails of a given distribution contain extreme values.\n\nA normal distribution has kurtosis exactly 3 (excess kurtosis exactly 0). Any distribution with kurtosis ≈3 (excess ≈0) is called mesokurtic. A distribution with kurtosis <3 (excess kurtosis <0) is called platykurtic. Compared to a normal distribution, its tails are shorter and thinner, and often its central peak is lower and broader. A distribution with kurtosis >3 (excess kurtosis >0) is called leptokurtic. Compared to a normal distribution, its tails are longer and fatter, and often its central peak is higher and sharper. \n\n##### Outliers: \nThey are data records that differ dramatically from all others, they distinguish themselves in one or more characteristics. In other words, an outlier is a value that escapes normality and can (and probably will) cause anomalies in the results obtained through algorithms and analytical systems.","metadata":{}},{"cell_type":"markdown","source":"##### Summary:\n1. Columns to remove because they are also correlated with other columns\n    - GarageArea\n    - 1stFlrSF\n    - TotRmsAbvGrd\n    - Id -> unique column\n2. Log-tranformation decreases the skewness and kurtosis value of the dataset\n3. The distribution of saleprice shows that above 500k is an outlier","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:50:59.794117Z","iopub.execute_input":"2024-08-01T17:50:59.794601Z","iopub.status.idle":"2024-08-01T17:51:02.036649Z","shell.execute_reply.started":"2024-08-01T17:50:59.794568Z","shell.execute_reply":"2024-08-01T17:51:02.034582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_columns = \"+\".join(cols)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:51:10.123673Z","iopub.execute_input":"2024-08-01T17:51:10.124394Z","iopub.status.idle":"2024-08-01T17:51:10.131799Z","shell.execute_reply.started":"2024-08-01T17:51:10.124347Z","shell.execute_reply":"2024-08-01T17:51:10.129702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_formula = \"SalePrice~\"+all_columns","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:51:31.719081Z","iopub.execute_input":"2024-08-01T17:51:31.719612Z","iopub.status.idle":"2024-08-01T17:51:31.726337Z","shell.execute_reply.started":"2024-08-01T17:51:31.719572Z","shell.execute_reply":"2024-08-01T17:51:31.724286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm = sm.OLS.from_formula(formula = my_formula, data = df)\nresult = lm.fit()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:51:37.193304Z","iopub.execute_input":"2024-08-01T17:51:37.193826Z","iopub.status.idle":"2024-08-01T17:51:37.239439Z","shell.execute_reply.started":"2024-08-01T17:51:37.193784Z","shell.execute_reply":"2024-08-01T17:51:37.237739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:51:58.56976Z","iopub.execute_input":"2024-08-01T17:51:58.571568Z","iopub.status.idle":"2024-08-01T17:51:58.659222Z","shell.execute_reply.started":"2024-08-01T17:51:58.571492Z","shell.execute_reply":"2024-08-01T17:51:58.657999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filtering correlated columns\ndf_clean = df[[x for x in df.columns if x not in ['GarageArea', '1stFlrSF', 'TotRmsAbvGrd', 'Id']]]\n\n# filterout above 500k saleprice\ndf_clean = df_clean[df_clean['SalePrice'] < 500000]\n\n# log-transformation\ndf_clean['SalePrice'] = np.log1p(df_clean['SalePrice'])\n\n#transform categorical columns\ndf_clean = pd.get_dummies(df_clean)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:53:07.07392Z","iopub.execute_input":"2024-08-01T17:53:07.075269Z","iopub.status.idle":"2024-08-01T17:53:07.152519Z","shell.execute_reply.started":"2024-08-01T17:53:07.075222Z","shell.execute_reply":"2024-08-01T17:53:07.150604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_clean.drop('SalePrice', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:53:22.313953Z","iopub.execute_input":"2024-08-01T17:53:22.31445Z","iopub.status.idle":"2024-08-01T17:53:22.589402Z","shell.execute_reply.started":"2024-08-01T17:53:22.314414Z","shell.execute_reply":"2024-08-01T17:53:22.588072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:55:32.993979Z","iopub.execute_input":"2024-08-01T17:55:32.994402Z","iopub.status.idle":"2024-08-01T17:55:33.000308Z","shell.execute_reply.started":"2024-08-01T17:55:32.994369Z","shell.execute_reply":"2024-08-01T17:55:32.998948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_clean.drop('SalePrice', axis = 1)\ny = df_clean['SalePrice']\n\ntrain_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.25, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:41:46.354627Z","iopub.execute_input":"2024-08-01T19:41:46.35523Z","iopub.status.idle":"2024-08-01T19:41:46.374976Z","shell.execute_reply.started":"2024-08-01T19:41:46.355112Z","shell.execute_reply":"2024-08-01T19:41:46.373175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_squared_error\n\nclass Model:\n    scores = {'Model':[], 'r2_score-train':[], 'mse-train':[], 'r2_score-test':[], 'mse-test':[]}\n    \n    def __init__(self, model, model_name):\n        self.model = model\n        self.model_name = model_name\n        \n    def predict(self):\n        self.model.fit(train_x, train_y)\n        \n        #training dataset pred\n        pred_train = self.model.predict(train_x)\n        r2_train = r2_score(train_y, pred_train)\n        mse_train = mean_squared_error(train_y, pred_train)\n        \n        #testing dataset pred\n        pred_test = self.model.predict(test_x)\n        r2_test = r2_score(test_y, pred_test)\n        mse_test = mean_squared_error(test_y, pred_test)\n        \n        self.performance(r2_train, mse_train, r2_test, mse_test)\n    \n    def performance(self, r2_train, mse_train, r2_test, mse_test):\n    \n        Model.scores['Model'].append(self.model_name)         \n        Model.scores['r2_score-test'].append(r2_test)\n        Model.scores['r2_score-train'].append(r2_train)\n        Model.scores['mse-test'].append(mse_test)\n        Model.scores['mse-train'].append(mse_train)\n        \n        print(\"**Training**\")\n        print(f'r2_score: {r2_train}')\n        print(f'mse: {mse_train}')\n        print(\"==========================================================\")\n        print(\"**Test**\")\n        print(f'r2_score: {r2_test}')\n        print(f'mse: {mse_test}')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:41:55.201078Z","iopub.execute_input":"2024-08-01T19:41:55.201536Z","iopub.status.idle":"2024-08-01T19:41:55.217254Z","shell.execute_reply.started":"2024-08-01T19:41:55.201502Z","shell.execute_reply":"2024-08-01T19:41:55.215221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Linear Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nmodel = Model(LinearRegression(), 'Regression')\nmodel.predict()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:57:56.620683Z","iopub.execute_input":"2024-08-01T17:57:56.621512Z","iopub.status.idle":"2024-08-01T17:57:56.89671Z","shell.execute_reply.started":"2024-08-01T17:57:56.621457Z","shell.execute_reply":"2024-08-01T17:57:56.894346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGBRegressor","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\nmodel = Model(XGBRegressor(), 'XGBRegressor')\nmodel.predict()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:59:14.609908Z","iopub.execute_input":"2024-08-01T17:59:14.610428Z","iopub.status.idle":"2024-08-01T17:59:15.726685Z","shell.execute_reply.started":"2024-08-01T17:59:14.610393Z","shell.execute_reply":"2024-08-01T17:59:15.721873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CatBoost Regressor","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\nmodel = Model(CatBoostRegressor(), 'CatBoostRegressor')\nmodel.predict()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T17:59:26.199173Z","iopub.execute_input":"2024-08-01T17:59:26.199615Z","iopub.status.idle":"2024-08-01T17:59:31.079056Z","shell.execute_reply.started":"2024-08-01T17:59:26.199579Z","shell.execute_reply":"2024-08-01T17:59:31.077737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Performance Summary","metadata":{}},{"cell_type":"code","source":"performance_df = pd.DataFrame(Model.scores)\nperformance_df.sort_values(by='r2_score-test', ascending=False, inplace=True)\nperformance_df.reset_index(drop = True, inplace = True)\nperformance_df","metadata":{"execution":{"iopub.status.busy":"2024-08-01T18:04:05.830555Z","iopub.execute_input":"2024-08-01T18:04:05.831223Z","iopub.status.idle":"2024-08-01T18:04:05.85446Z","shell.execute_reply.started":"2024-08-01T18:04:05.831175Z","shell.execute_reply":"2024-08-01T18:04:05.853066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Ridge","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nmodel = Model(Ridge(alpha=1.0), 'Ridge')\nmodel.predict()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:27:09.074633Z","iopub.execute_input":"2024-08-01T19:27:09.075227Z","iopub.status.idle":"2024-08-01T19:27:09.102709Z","shell.execute_reply.started":"2024-08-01T19:27:09.075182Z","shell.execute_reply":"2024-08-01T19:27:09.10124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Lasso","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nmodel = Model(Lasso(alpha=0), 'Lasso')\nmodel.predict()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:27:10.719422Z","iopub.execute_input":"2024-08-01T19:27:10.719918Z","iopub.status.idle":"2024-08-01T19:27:10.742785Z","shell.execute_reply.started":"2024-08-01T19:27:10.719857Z","shell.execute_reply":"2024-08-01T19:27:10.740923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using AutoML","metadata":{}},{"cell_type":"markdown","source":"#### This part will be one time running, as this only need to search for the most optimized parameters","metadata":{}},{"cell_type":"code","source":"import tpot\n\nfrom tpot import TPOTRegressor\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n\ncv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\ntpot = TPOTRegressor(generations=5, population_size=50, verbosity=2, random_state = 1, n_jobs = -1)\n\ntpot.fit(train_x, train_y)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:44:07.21986Z","iopub.execute_input":"2024-08-01T19:44:07.221922Z","iopub.status.idle":"2024-08-01T19:58:14.117585Z","shell.execute_reply.started":"2024-08-01T19:44:07.221839Z","shell.execute_reply":"2024-08-01T19:58:14.116007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tpot.score(test_x, test_y))\ntpot.export('HousePricePred - AutoML.py')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:58:14.120624Z","iopub.execute_input":"2024-08-01T19:58:14.121192Z","iopub.status.idle":"2024-08-01T19:58:14.174648Z","shell.execute_reply.started":"2024-08-01T19:58:14.121122Z","shell.execute_reply":"2024-08-01T19:58:14.172984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tpot = TPOTRegressor(generations=15, population_size=50, verbosity=2, random_state = 1, n_jobs = -1)\n\ntpot.fit(train_x, train_y)\nprint(tpot.score(test_x, test_y))\ntpot.export('HousePricePred - AutoML gen15.py')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T19:58:31.890358Z","iopub.execute_input":"2024-08-01T19:58:31.890934Z","iopub.status.idle":"2024-08-01T20:31:38.569008Z","shell.execute_reply.started":"2024-08-01T19:58:31.890873Z","shell.execute_reply":"2024-08-01T20:31:38.564752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = {'Model':[], 'r2_score-train':[], 'mse-train':[], 'r2_score-test':[], 'mse-test':[]}\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LassoLarsCV, RidgeCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom tpot.builtins import StackingEstimator\nfrom sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\nfrom tpot.export_utils import set_param_recursive\n\n# # NOTE: Make sure that the outcome column is labeled 'target' in the data file\n# tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n# features = tpot_data.drop('target', axis=1)\n# training_features, testing_features, training_target, testing_target = \\\n#             train_test_split(features, tpot_data['target'], random_state=1)\n\n# Average CV score on the training set was: -0.013978187312131077\nexported_pipeline = make_pipeline(\n    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n    RandomForestRegressor(bootstrap=True, max_features=0.8500000000000001, min_samples_leaf=3, min_samples_split=17, n_estimators=100)\n)\n# Fix random state for all the steps in exported pipeline\nset_param_recursive(exported_pipeline.steps, 'random_state', 1)\n\n\n\nexported_pipeline.fit(train_x, train_y)\nresults = exported_pipeline.predict(test_x)\n\n\n#training dataset pred\nresults = exported_pipeline.predict(train_x)\nr2_train = r2_score(train_y, results)\nmse_train = mean_squared_error(train_y, results)\n\n#testing dataset pred\nresults = exported_pipeline.predict(test_x)\nr2_test = r2_score(test_y, results)\nmse_test = mean_squared_error(test_y, results)\n\n\nscores['Model'].append('AutoML - 15 generation')\nscores['r2_score-train'].append(r2_train)\nscores['mse-train'].append(mse_train)\nscores['r2_score-test'].append(r2_test)\nscores['mse-test'].append(mse_test)\n\nprint(\"**Training**\")\nprint(f'r2_score: {r2_train}')\nprint(f'mse: {mse_train}')\nprint(\"==========================================================\")\nprint(\"**Test**\")\nprint(f'r2_score: {r2_test}')\nprint(f'mse: {mse_test}')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T20:34:05.656549Z","iopub.execute_input":"2024-08-01T20:34:05.656991Z","iopub.status.idle":"2024-08-01T20:34:08.049304Z","shell.execute_reply.started":"2024-08-01T20:34:05.656961Z","shell.execute_reply":"2024-08-01T20:34:08.047419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = {'Model':[], 'r2_score-train':[], 'mse-train':[], 'r2_score-test':[], 'mse-test':[]}\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LassoLarsCV, RidgeCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom tpot.builtins import StackingEstimator\nfrom sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\nfrom tpot.export_utils import set_param_recursive\n\n# # NOTE: Make sure that the outcome column is labeled 'target' in the data file\n# tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n# features = tpot_data.drop('target', axis=1)\n# training_features, testing_features, training_target, testing_target = \\\n#             train_test_split(features, tpot_data['target'], random_state=1)\n\n# Average CV score on the training set was: -0.015860838312438157\nexported_pipeline = make_pipeline(\n    StackingEstimator(estimator=RidgeCV()),\n    RandomForestRegressor(bootstrap=True, max_features=0.45, min_samples_leaf=3, min_samples_split=20, n_estimators=100)\n)\n# Fix random state for all the steps in exported pipeline\nset_param_recursive(exported_pipeline.steps, 'random_state', 1)\n\n\n\nexported_pipeline.fit(train_x, train_y)\nresults = exported_pipeline.predict(test_x)\n\n\n#training dataset pred\nresults = exported_pipeline.predict(train_x)\nr2_train = r2_score(train_y, results)\nmse_train = mean_squared_error(train_y, results)\n\n#testing dataset pred\nresults = exported_pipeline.predict(test_x)\nr2_test = r2_score(test_y, results)\nmse_test = mean_squared_error(test_y, results)\n\n\nscores['Model'].append('AutoML - 10 generation')\nscores['r2_score-train'].append(r2_train)\nscores['mse-train'].append(mse_train)\nscores['r2_score-test'].append(r2_test)\nscores['mse-test'].append(mse_test)\n\nprint(\"**Training**\")\nprint(f'r2_score: {r2_train}')\nprint(f'mse: {mse_train}')\nprint(\"==========================================================\")\nprint(\"**Test**\")\nprint(f'r2_score: {r2_test}')\nprint(f'mse: {mse_test}')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T20:31:39.732421Z","iopub.execute_input":"2024-08-01T20:31:39.733687Z","iopub.status.idle":"2024-08-01T20:31:40.864057Z","shell.execute_reply.started":"2024-08-01T20:31:39.733622Z","shell.execute_reply":"2024-08-01T20:31:40.859823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance_df = pd.concat([performance_df,pd.DataFrame(scores)]).sort_values(by = ['r2_score-test'], ascending = False)\nperformance_df.reset_index(drop = True, inplace = True)\nperformance_df['Dimension-Reduction'] = \"None\"\nperformance_df","metadata":{"execution":{"iopub.status.busy":"2024-08-01T20:34:33.193482Z","iopub.execute_input":"2024-08-01T20:34:33.193949Z","iopub.status.idle":"2024-08-01T20:34:33.222437Z","shell.execute_reply.started":"2024-08-01T20:34:33.193916Z","shell.execute_reply":"2024-08-01T20:34:33.220805Z"},"trusted":true},"execution_count":null,"outputs":[]}]}